<!doctype html>
<html>
<head>
	<meta charset="utf-8" />
    <meta name="description" content="Modibo Camara's website. I'm an Econ PhD student at Northwestern.">
    <meta name="author" content="Modibo Camara">
	<!--<link href="main.css" rel="stylesheet" />-->
	<title>Modibo Camara's website</title>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <link rel="stylesheet" href="https://latex.now.sh/style.css">
    <link rel="stylesheet" href="main.css">
</head>
<body>

    <header>
        <h1>Modibo Camara, PhD Student</h1>
        <p><center><img border="2px solid #555" src="photo.png" width="40%" loading="lazy"></center></p>
        <p>Welcome! I'm a fifth-year Economics PhD student at Northwestern University. My email is <a href="mailto:mcamara@u.northwestern.edu">mcamara@u.northwestern.edu</a>. My office is KGH 3368. My twitter handle is <a href="https://twitter.com/modibokhane">@modibokhane</a>.</p>

        <p>My research is in <b>mechanism design</b> as well as <b>bounded rationality</b>, but I am broadly interested in the design of economic and social institutions. To that end, I borrow heavily from ideas and methods in theoretical computer science and statistics.</p>

        <p>Recent news:
        <ul>
            <li>I'm presenting <i>High-Dimensional Decision Theory</i> at the 2020 European Winter Meeting of the Econometric Society, the Young Economists Symposium 2020, and the 15th Economic Graduate Students Conference. 
            <li><i>Mechanisms for a No-Regret Agent</i> was accepted to <b>FOCS 2020</b>, a top peer-reviewed conference in theoretical computer science.</li>
            <li>I spent the summer of 2020 as an intern at <b>Microsoft Research NYC</b>, working with Nicole Immorlica, Brendan Lucier, and others on research in EconCS.</li>
        </ul></p>

        <!--<p>Here's a quick bio in lieu of a CV.</p>
        <ul>
            <li>I graduated in 2016 from the University of Pennsylvania, with majors in economics and math. I also have an M.A. in economics from Northwestern.</li>
            <li>I have done internships at Microsoft Research (2020), the Federal Reserve Board (2015), and the Commodity Futures Trading Commission (2014).</li>
            <li>I am grateful to be co-advised by Eddie Dekel (Econ) and Jason Hartline (CS).</li>
        </ul>-->
    </header>

    <section width=1000px>
        <h2>Research</h2>
        
        Here's what I'm working on.<!-- If I don't link to a draft, it's available by request.-->

        <h4><a href="https://arxiv.org/abs/2009.05518">Mechanisms for a No-Regret Agent: Beyond the Common Prior</a> <!--(<a href="https://conference2.aau.at/event/4/contributions/173/">30-min talk</a>)</h4>-->

        <h5>To appear FOCS 2020. Joint with <a href="https://sites.northwestern.edu/hartline/">Jason Hartline</a> and <a href="http://users.eecs.northwestern.edu/~acj861/">Aleck Johnsen</a>.</h5>
        <center>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/Bt3IVL691Wg"></iframe>
        </center>

        <p>A rich class of mechanism design problems can be understood as incomplete-information games between a principal who commits to a policy and an agent who responds, with payoffs determined by an unknown state of the world. Traditionally, these models require strong and often-impractical assumptions about beliefs (a common prior over the state). In this paper, we dispense with the common prior. Instead, we consider a repeated interaction where both the principal and the agent may learn over time from the state history. We reformulate mechanism design as a reinforcement learning problem and develop mechanisms that attain natural benchmarks without any assumptions on the state-generating process. Our results make use of novel behavioral assumptions for the agent -- centered around <i>counterfactual internal regret</i> -- that capture the spirit of rationality without relying on beliefs.</p>

        <h4><a href="high-dimensional-decision-theory.pdf">High-Dimensional Decision Theory</a> <!--(<a href="https://www.youtube.com/watch?v=hyPxG3eeVXA">1-min talk</a>)--></h4>

        <p>In economic theory, rationality assumptions are used to make predictions about choice behavior. However, because life involves so many decisions, rationality in practice means solving a high-dimensional optimization problem. This can be computationally hard. In this paper, I introduce a model of high-dimensional choice under uncertainty, along with an axiom of computational tractability, to ask two questions. First, can tractability axioms, paired with rationality axioms, be used to obtain tighter predictions for choice behavior? I prove two representation theorems that provide an affirmative answer, by characterizing the set of tractable and rationalizable choice rules. In particular, one of the representations corresponds to a heuristic known as narrow choice bracketing. Second, when tractability constraints bind, will a self-interested decision-maker make rationalizable choices? Not necessarily. I show that for many intractable utility functions, no rationalizable algorithm obtains a constant approximation, yet every such algorithm is weakly dominated by an irrational algorithm that does.</p>

        
    </section>

    <footer>
        <br><hr>
        <p>This page was last modified on <span id="demo"></span>.</p>
        <script>
            var d = new Date(document.lastModified);
            document.getElementById("demo").innerHTML = d.toDateString();
        </script>
    </footer>

    <div id="all"><!--width="300"-->

        

        <!--<div id="nav"></div>
        <script>
        $("#nav").load("nav.html");
        </script>-->
       
        <div id="main">

            


            <a name="about"></a>
            

            <!-- <p>Previously, I was an undergraduate at the University of Pennsylvania (majors in econ and math, minor in compsci). I spent two incredible summers at the Federal Reserve Board and the Commodity Futures Trading Commission.</p>

            <p>My dissertation committee includes Eddie Dekel (co-chair), Jeff Ely, Jason Hartline (co-chair), and Marciano Siniscalchi. But all weird opinions are my own.</p>

            <p>Along with Lorenzo Stanca and Xiaoyu Cheng, I occasionally organize a reading group in economic theory. If you want to join the mailing list or want to present something, shoot me an email!</p>

            <p>Teaching: ugrad economics of medicine, applied econometrics, intermediate micro II; grad econometrics II, econometrics III. RAing for CET and Eddie.</p> -->
            <a name="papers"></a>
            <div class="divider"></div>
            <div>
                

            </div>

            <a name="research"></a>
            <div class="divider"></div>

            <!--<div>
                <h3>Dissertation Research</h3>

                <p>Economists predict behavior using a simple identifying assumption: that economic agents act in their own best interest. We tend to define "best interest" narrowly enough to derive useful conclusions from a given model, but broadly enough to include certain behaviors that we see empirically. Along the way, we acknowledge that many of our models assume a level of competence that we ourselves would find difficult to satisfy. But only rarely do we take advantage of the fact that statisticians and computer scientists have spent decades formalizing the ways in which decision problems are difficult, and characterizing the difficulty that state-of-the-art methods can handle.</p>

                <p>So: can we leverage theories of complexity to weaken or strengthen our behavioral assumptions in a way that (a) makes our theory more credible, where needed, (b) justifies existing theory, where possible, and (c) modifies our predictions appropriately as a problem becomes more complicated? Can these revised models explain real-world phenomena that are difficult or impossible to express via existing models? My dissertation research answers these questions affirmatively.</p>

                <p>In particular, my work uses a three-step methodology to revise classic models in mechanism design and decision theory. It is easy to describe in the abstract (although the execution can be more intricate). Given an existing model:</p>
                <ol>
                    <li>Figure out what we're asking agents to do and how real-world experts would accomplish that task.</li>
                    <li>Identify the performance benchmarks that real-world experts can guarantee (resp. that are impossible to achieve).</li>
                    <li>Assume that agents weakly overperform (resp. strictly underperform) those benchmarks.</li>
                </ol>
            </div>


            <a name="thoughts"></a>
            <div class="divider"></div>
            <div>
                <h3>Miscellaneous</h3>
                <p>I'll occasionally write about topics that I'm interested in and/or opinions that I'd like to express. See the links below.</p>
                <ul>
                    <li><a href="social-engineering.html">A Path Towards Social Engineering</a></li>
                    <li><a href="partial-choice.html">Observability Issues in Decision Theory</a></li>
                </ul>
                <p>Please feel free to reach out if anything interests you.</p>
            </div>-->
        </div>
    </div>
</body>
</html>